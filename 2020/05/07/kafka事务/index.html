<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="我的个人博客"><title>kafka：事务原理 | SvizzerChow's Blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">kafka：事务原理</h1><a id="logo" href="/.">SvizzerChow's Blog</a><p class="description">Leaning</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">kafka：事务原理</h1><div class="post-meta">May 7, 2020<span> | </span><span class="category"><a href="/categories/kafka/">kafka</a></span></div><div class="post-content"><meta name="referrer" content="no-referrer">

<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><h3 id="Broker-Config"><a href="#Broker-Config" class="headerlink" title="Broker Config"></a>Broker Config</h3><p>broker端可以什么都不配置即可使用。</p>
<ol>
<li><strong>ransactional.id.timeout.ms：</strong></li>
</ol>
<p>在ms中，事务协调器在生产者TransactionalId提前过期之前等待的最长时间，并且没有从该生产者TransactionalId接收到任何事务状态更新。默认是604800000(7天)。这允许每周一次的生产者作业维护它们的id</p>
<ol start="2">
<li><strong>max.transaction.timeout.ms</strong></li>
</ol>
<p>事务允许的最大超时。如果客户端请求的事务时间超过此时间，broke将在InitPidRequest中返回InvalidTransactionTimeout错误。这可以防止客户机超时过大，从而导致用户无法从事务中包含的主题读取内容。<br>默认值为900000(15分钟)。这是消息事务需要发送的时间的保守上限。</p>
<ol start="3">
<li><strong>transaction.state.log.replication.factor</strong></li>
</ol>
<p>事务状态topic的副本数量。默认值:3</p>
<ol start="4">
<li><strong>transaction.state.log.num.partitions</strong></li>
</ol>
<p>事务状态主题的分区数。默认值:50</p>
<ol start="5">
<li><strong>transaction.state.log.min.isr</strong></li>
</ol>
<p>事务状态主题的每个分区ISR最小数量。默认值:2</p>
<ol start="6">
<li><strong>transaction.state.log.segment.bytes</strong></li>
</ol>
<p>事务状态主题的segment大小。默认值:104857600字节</p>
<h3 id="Producer-Config"><a href="#Producer-Config" class="headerlink" title="Producer Config"></a>Producer Config</h3><ol>
<li><strong>enable.idempotence：</strong></li>
</ol>
<p>开启幂等</p>
<ol start="2">
<li><strong>transaction.timeout.ms</strong>：</li>
</ol>
<p>事务超时时间<br>事务协调器在主动中止正在进行的事务之前等待生产者更新事务状态的最长时间。<br>这个配置值将与InitPidRequest一起发送到事务协调器。如果该值大于max.transaction.timeout。在broke中设置ms时，请求将失败，并出现InvalidTransactionTimeout错误。<br>默认是60000。这使得交易不会阻塞下游消费超过一分钟，这在实时应用程序中通常是允许的。</p>
<ol start="3">
<li><strong>transactional.id:</strong></li>
</ol>
<p>用于事务性交付的TransactionalId。这支持跨多个生产者会话的可靠性语义，因为它允许客户端确保使用相同TransactionalId的事务在启动任何新事务之前已经完成。如果没有提供TransactionalId，则生产者仅限于幂等交付。</p>
<h3 id="Consumer-Config"><a href="#Consumer-Config" class="headerlink" title="Consumer Config"></a>Consumer Config</h3><ol>
<li><strong>isolation.level</strong></li>
</ol>
<ul>
<li>read_uncommitted:以偏移顺序使用已提交和未提交的消息。</li>
<li>read_committed:仅以偏移量顺序使用非事务性消息或已提交事务性消息。为了维护偏移排序，这个设置意味着我们必须在使用者中缓冲消息，直到看到给定事务中的所有消息。</li>
</ul>
<h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><p>这个例子的核心是观察事务开启对其它没有开启事务消息的影响，即消费者消费的顺序。</p>
<h3 id="Producer"><a href="#Producer" class="headerlink" title="Producer"></a>Producer</h3><p>一个生产者开启事务发消息，另一个生产者不开启事务写消息，可以观察消费者获取这些消息的时间。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MessageTransactionProduct</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> String KAFKA_SERVERS = <span class="string">"192.168.56.10:9092"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(<span class="string">"bootstrap.servers"</span>, KAFKA_SERVERS);</span><br><span class="line">        <span class="comment">//props.put("metadata.broker.list", KAFKA_SERVERS);</span></span><br><span class="line">        props.put(<span class="string">"zk.connect"</span>, <span class="string">"192.168.56.10:2181/kafka,192.168.56.10:2182/kafka,192.168.56.10:2183/kafka"</span>);</span><br><span class="line">        props.put(<span class="string">"acks"</span>, <span class="string">"all"</span>);</span><br><span class="line">        props.put(<span class="string">"key.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        props.put(<span class="string">"value.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        props.put(<span class="string">"enable.idempotence"</span>, <span class="keyword">true</span>);</span><br><span class="line">        props.put(<span class="string">"transactional.id"</span>, <span class="string">"1"</span>);</span><br><span class="line">        props.put(<span class="string">"transaction.timeout.ms"</span>, <span class="string">"10000"</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        Producer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</span><br><span class="line">        Producer&lt;String, String&gt; producer2 = init(<span class="number">2</span>);</span><br><span class="line">        <span class="comment">//producer.send(new ProducerRecord&lt;String, String&gt;("test", 0, Integer.toString(-1), Integer.toString(-1)));</span></span><br><span class="line">        producer.initTransactions();</span><br><span class="line">        producer.beginTransaction();</span><br><span class="line">        System.out.println(System.currentTimeMillis());</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">121</span>; i &lt; <span class="number">130</span>; i++) &#123;</span><br><span class="line">                producer.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">"test"</span>, <span class="number">0</span>, Integer.toString(i), Integer.toString(i)));</span><br><span class="line">            &#125;</span><br><span class="line">            Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">            System.out.println(System.currentTimeMillis());</span><br><span class="line">            <span class="comment">// 模拟另一个生产者写入消息</span></span><br><span class="line">            producer2.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">"test"</span>, <span class="number">0</span>, Integer.toString(-<span class="number">2</span>), Integer.toString(-<span class="number">2</span>)));</span><br><span class="line">            Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">            System.out.println(System.currentTimeMillis());</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">131</span>; i &lt; <span class="number">160</span>; i++) &#123;</span><br><span class="line">                producer.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">"test"</span>, <span class="number">0</span>, Integer.toString(i), Integer.toString(i)));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">            producer.commitTransaction();</span><br><span class="line">            producer.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Producer&lt;String, String&gt; <span class="title">init</span><span class="params">(<span class="keyword">int</span> id)</span></span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(<span class="string">"bootstrap.servers"</span>, KAFKA_SERVERS);</span><br><span class="line">        <span class="comment">//props.put("metadata.broker.list", KAFKA_SERVERS);</span></span><br><span class="line">        props.put(<span class="string">"zk.connect"</span>, <span class="string">"192.168.56.10:2181/kafka,192.168.56.10:2182/kafka,192.168.56.10:2183/kafka"</span>);</span><br><span class="line">        props.put(<span class="string">"acks"</span>, <span class="string">"all"</span>);</span><br><span class="line">        props.put(<span class="string">"key.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        props.put(<span class="string">"value.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        props.put(<span class="string">"enable.idempotence"</span>, <span class="keyword">false</span>);</span><br><span class="line">        <span class="comment">//props.put("transactional.id", id+"");</span></span><br><span class="line">        props.put(<span class="string">"transaction.timeout.ms"</span>, <span class="string">"10000"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MessageConsumer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.setProperty(<span class="string">"bootstrap.servers"</span>, MessageProduct.KAFKA_SERVERS);</span><br><span class="line">        props.put(<span class="string">"client.id"</span>, <span class="string">"1"</span>);</span><br><span class="line">        props.setProperty(<span class="string">"group.id"</span>, <span class="string">"test"</span>);</span><br><span class="line">        props.setProperty(<span class="string">"enable.auto.commit"</span>, <span class="string">"true"</span>);</span><br><span class="line">        props.setProperty(<span class="string">"auto.commit.interval.ms"</span>, <span class="string">"1000"</span>);</span><br><span class="line">        props.setProperty(<span class="string">"key.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">        props.setProperty(<span class="string">"value.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">        props.setProperty(<span class="string">"isolation.level"</span>, <span class="string">"read_committed"</span>);</span><br><span class="line">        Consumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line">        consumer.subscribe(Arrays.asList(<span class="string">"test"</span>));</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(<span class="number">1000</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                System.out.printf(System.currentTimeMillis()+<span class="string">" offset = %d, key = %s, value = %s%n"</span>, record.offset(), record.key(), record.value());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>观察消费者的消费结果可以看到：</p>
<ol>
<li>没有事务的消息如果在事务消息开始之前发送：消费者能先消费到没有事务的消息；</li>
<li>没有事务的消息如果在事务消息开始之后发送：消费者要等到事务完成/中断之后才能消费到没有开启事务的消息。</li>
</ol>
<h2 id="Producer事务原理"><a href="#Producer事务原理" class="headerlink" title="Producer事务原理"></a>Producer事务原理</h2><p>官方的Data Flow</p>
<p><img src="https://cdn.nlark.com/yuque/0/2020/png/168294/1588838992214-f13916cc-36d8-4816-8c61-73098cb0076b.png#align=left&amp;display=inline&amp;height=546&amp;margin=%5Bobject%20Object%5D&amp;originHeight=546&amp;originWidth=720&amp;size=0&amp;status=done&amp;style=none&amp;width=720" alt><br>事务和消费者组有些类似，有一个Broker作为事务协调器(Transaction Coordinator)。生产者对应的事务协调器是根据<strong>transaction_state主题的分区确定，生产者的TransactionalId的哈希值对</strong>transaction_state主题分区数取余对应的分区即为对应的事务协调器节点。</p>
<h3 id="事务流程"><a href="#事务流程" class="headerlink" title="事务流程"></a>事务流程</h3><p>部分修改的Data Flow<br><img src="https://cdn.nlark.com/yuque/0/2020/png/168294/1588839569472-0bfa53ec-6d3c-459e-81e5-2b8ab45c2a54.png#align=left&amp;display=inline&amp;height=1515&amp;margin=%5Bobject%20Object%5D&amp;originHeight=1515&amp;originWidth=2835&amp;size=0&amp;status=done&amp;style=none&amp;width=2835" alt></p>
<p>####<br>安装事务的流程画了一幅序列图，更好的展示请求的流程。<br><img src="https://cdn.nlark.com/yuque/0/2020/png/168294/1588851711614-052734c4-77c0-4176-8c5d-05489d7b3c15.png#align=left&amp;display=inline&amp;height=870&amp;margin=%5Bobject%20Object%5D&amp;name=kafka%E4%BA%8B%E5%8A%A1%E7%94%9F%E4%BA%A7%E8%80%85.png&amp;originHeight=870&amp;originWidth=894&amp;size=53599&amp;status=done&amp;style=none&amp;width=894" alt="kafka事务生产者.png"></p>
<h4 id="事务初始化initTransactions"><a href="#事务初始化initTransactions" class="headerlink" title="事务初始化initTransactions()"></a>事务初始化initTransactions()</h4><ol>
<li>查找事务协调器节点</li>
</ol>
<p>Transaction Producer 会向 Broker （随机选择一台 broker，一般选择本地连接最少的这台 broker）发送 FindCoordinatorRequest 请求，获取其 TransactionCoordinator。</p>
<blockquote>
<p>def partitionFor(transactionalId: String): Int = Utils.abs(transactionalId.hashCode) % transactionTopicPartitionCount</p>
</blockquote>
<ol start="2">
<li>获取PID</li>
</ol>
<p><a href="http://matt33.com/2018/10/24/kafka-idempotent/#PID" target="_blank" rel="noopener">Producer ID</a><br>Transaction Producer 在 <code>initializeTransactions()</code> 方法中会向 TransactionCoordinator 发送 InitPidRequest 请求获取其分配的 PID，有了 PID，事务写入时可以保证幂等性，PID 如何分配可以参考 <a href="http://matt33.com/2018/10/24/kafka-idempotent/#Producer-PID-%E7%94%B3%E8%AF%B7" target="_blank" rel="noopener">PID 分配</a>，但是 TransactionCoordinator 在给事务 Producer 分配 PID 会做一些判断，主要的内容是：</p>
<ol>
<li>如果这个 txn.id 之前没有相应的事务状态（new txn.id），那么会初始化其事务 meta 信息 TransactionMetadata（会给其分配一个 PID，初始的 epoch 为-1），如果有事务状态，获取之前的状态；</li>
<li>校验其 TransactionMetadata 的状态信息（参考下面代码中 <code>prepareInitProduceIdTransit()</code> 方法）：<ol>
<li>如果前面还有状态转移正在进行，直接返回 CONCURRENT_TRANSACTIONS 异常；</li>
<li>如果此时的状态为 PrepareAbort 或 PrepareCommit，返回 CONCURRENT_TRANSACTIONS 异常；</li>
<li>如果之前的状态为 CompleteAbort、CompleteCommit 或 Empty，那么先将状态转移为 Empty，然后更新一下 epoch 值；</li>
<li>如果之前的状态为 Ongoing，状态会转移成 PrepareEpochFence，然后再 abort 当前的事务，并向 client 返回 CONCURRENT_TRANSACTIONS 异常；</li>
<li>如果状态为 Dead 或 PrepareEpochFence，直接抛出相应的 FATAL 异常；</li>
</ol>
</li>
<li>将 txn.id 与相应的 TransactionMetadata 持久化到事务日志中，对于 new txn.id，这个持久化的数据主要时 txn.id 与 pid 关系信息，如图中的 3a 所示。</li>
</ol>
<h4 id="开始事务beginTransaction"><a href="#开始事务beginTransaction" class="headerlink" title="开始事务beginTransaction()"></a>开始事务beginTransaction()</h4><p>前面两步都是 Transaction Producer 调用 <code>initTransactions()</code> 部分，到这里，Producer 可以调用 <code>beginTransaction()</code> 开始一个事务操作，其实现方法如下面所示：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//KafkaProducer</span></span><br><span class="line"><span class="comment">//note: 应该在一个事务操作之前进行调用</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">beginTransaction</span><span class="params">()</span> <span class="keyword">throws</span> ProducerFencedException </span>&#123;</span><br><span class="line">    throwIfNoTransactionManager();</span><br><span class="line">    transactionManager.beginTransaction();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// TransactionManager</span></span><br><span class="line"><span class="comment">//note: 在一个事务开始之前进行调用，这里实际上只是转换了状态（只在 producer 本地记录了状态的开始）</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">beginTransaction</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    ensureTransactional();</span><br><span class="line">    maybeFailWithError();</span><br><span class="line">    transitionTo(State.IN_TRANSACTION);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这里只是将本地事务状态转移成 IN_TRANSACTION，并没有与 Server 端进行交互，所以在流程图中没有体现出来（TransactionManager 初始化时，其状态为 UNINITIALIZED，Producer 调用 <code>initializeTransactions()</code> 方法，其状态转移成 INITIALIZING）。</p>
<h4 id="事务过程"><a href="#事务过程" class="headerlink" title="事务过程"></a>事务过程</h4><p>这个过程中就是正常的发送消息即可。</p>
<p>如果有比较典型的场景：先通过Consumer获取消息，然后处理数据然后通过Producer写入Topic中；这就是典型的Consume-Porcess-Produce Loop场景，对于这种场景有特殊的API:<strong> sendOffsetsToTransaction</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    ConsumerRecords records = consumer.poll(Long.MAX_VALUE);</span><br><span class="line">    producer.beginTransaction();</span><br><span class="line">    <span class="comment">//start</span></span><br><span class="line">    <span class="keyword">for</span> (ConsumerRecord record : records)&#123;</span><br><span class="line">        producer.send(producerRecord(“outputTopic1”, record));</span><br><span class="line">        producer.send(producerRecord(“outputTopic2”, record));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 这里写消费位移</span></span><br><span class="line">    producer.sendOffsetsToTransaction(currentOffsets(consumer), group);</span><br><span class="line">    <span class="comment">//end</span></span><br><span class="line">    producer.commitTransaction();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>对于事务过程/流程解析一下，序号按照上图。</p>
<h5 id="4-1-AddPartitionsToTxnRequest"><a href="#4-1-AddPartitionsToTxnRequest" class="headerlink" title="4.1 AddPartitionsToTxnRequest"></a>4.1 AddPartitionsToTxnRequest</h5><p>Producer 在调用 <code>send()</code> 方法时，Producer 会将这个对应的 Topic—Partition 添加到 TransactionManager 的记录中，如下所示：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//note: 如何开启了幂等性或事务性，需要做一些处理</span></span><br><span class="line"><span class="keyword">if</span> (transactionManager != <span class="keyword">null</span> &amp;&amp; transactionManager.isTransactional())</span><br><span class="line">    transactionManager.maybeAddPartitionToTransaction(tp);</span><br></pre></td></tr></table></figure></p>
<p>如果这个 Topic-Partition 之前不存在，那么就添加到 newPartitionsInTransaction 集合中，如下所示：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//note: 将 tp 添加到 newPartitionsInTransaction 中，记录当前进行事务操作的 tp</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">maybeAddPartitionToTransaction</span><span class="params">(TopicPartition topicPartition)</span> </span>&#123;</span><br><span class="line">    failIfNotReadyForSend();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//note: 如果 partition 已经添加到 partitionsInTransaction、pendingPartitionsInTransaction、newPartitionsInTransaction中</span></span><br><span class="line">    <span class="keyword">if</span> (isPartitionAdded(topicPartition) || isPartitionPendingAdd(topicPartition))</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    log.debug(<span class="string">"Begin adding new partition &#123;&#125; to transaction"</span>, topicPartition);</span><br><span class="line">    newPartitionsInTransaction.add(topicPartition);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Producer 端的 Sender 线程会将这个信息通过 AddPartitionsToTxnRequest 请求发送给 TransactionCoordinator，也就是图中的 <strong>4.1 </strong>过程，TransactionCoordinator 会将这个 Topic-Partition 列表更新到 txn.id 对应的 TransactionMetadata 中，并且会持久化到事务日志中，也就是图中的<strong> 4.1 a </strong>部分，这里持久化的数据主要是 txn.id 与其涉及到的 Topic-Partition 信息。</p>
<h5 id="4-2-ProduceRequest"><a href="#4-2-ProduceRequest" class="headerlink" title="4.2 ProduceRequest"></a>4.2 ProduceRequest</h5><p>这一步与正常 Producer 写入基本上一样，就是相应的 Leader 在持久化数据时会在头信息中标识这条数据是不是来自事务 Producer 的写入（主要是数据协议有变动，Server 处理并不需要做额外的处理）。</p>
<h5 id="4-3-AddOffsetsToTxnRequest"><a href="#4-3-AddOffsetsToTxnRequest" class="headerlink" title="4.3 AddOffsetsToTxnRequest"></a>4.3 AddOffsetsToTxnRequest</h5><p>Producer 在调用 <code>sendOffsetsToTransaction()</code> 方法时，第一步会首先向 TransactionCoordinator 发送相应的 AddOffsetsToTxnRequest 请求，如下所示：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//class KafkaProcducer</span></span><br><span class="line"><span class="comment">//note: 当你需要 batch 的消费-处理-写入消息，这个方法需要被使用</span></span><br><span class="line"><span class="comment">//note: 发送指定的 offset 给 group coordinator，用来标记这些 offset 是作为当前事务的一部分，只有这次事务成功时</span></span><br><span class="line"><span class="comment">//note: 这些 offset 才会被认为 commit 了</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sendOffsetsToTransaction</span><span class="params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     String consumerGroupId)</span> <span class="keyword">throws</span> ProducerFencedException </span>&#123;</span><br><span class="line">    throwIfNoTransactionManager();</span><br><span class="line">    TransactionalRequestResult result = transactionManager.sendOffsetsToTransaction(offsets, consumerGroupId);</span><br><span class="line">    sender.wakeup();</span><br><span class="line">    result.await();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// class TransactionManager</span></span><br><span class="line"><span class="comment">//note: 发送 AddOffsetsToTxRequest</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> TransactionalRequestResult <span class="title">sendOffsetsToTransaction</span><span class="params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                                        String consumerGroupId)</span> </span>&#123;</span><br><span class="line">    ensureTransactional();</span><br><span class="line">    maybeFailWithError();</span><br><span class="line">    <span class="keyword">if</span> (currentState != State.IN_TRANSACTION)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> KafkaException(<span class="string">"Cannot send offsets to transaction either because the producer is not in an "</span> +</span><br><span class="line">                <span class="string">"active transaction"</span>);</span><br><span class="line"></span><br><span class="line">    log.debug(<span class="string">"Begin adding offsets &#123;&#125; for consumer group &#123;&#125; to transaction"</span>, offsets, consumerGroupId);</span><br><span class="line">    AddOffsetsToTxnRequest.Builder builder = <span class="keyword">new</span> AddOffsetsToTxnRequest.Builder(transactionalId,</span><br><span class="line">            producerIdAndEpoch.producerId, producerIdAndEpoch.epoch, consumerGroupId);</span><br><span class="line">    AddOffsetsToTxnHandler handler = <span class="keyword">new</span> AddOffsetsToTxnHandler(builder, offsets);</span><br><span class="line">    enqueueRequest(handler);</span><br><span class="line">    <span class="keyword">return</span> handler.result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>TransactionCoordinator 在收到这个请求时，处理方法与 <strong>4.1</strong> 中的一样，把这个 group.id 对应的 <code>__consumer_offsets</code> 的 Partition （与写入涉及的 Topic-Partition 一样）保存到事务对应的 meta 中，之后会持久化相应的事务日志，如图中 <strong>4.3a </strong>所示。</p>
<h5 id="4-4-TxnOffsetsCommitRequest"><a href="#4-4-TxnOffsetsCommitRequest" class="headerlink" title="4.4 TxnOffsetsCommitRequest"></a>4.4 TxnOffsetsCommitRequest</h5><p>Producer 在收到 TransactionCoordinator 关于 AddOffsetsToTxnRequest 请求的结果后，后再次发送 TxnOffsetsCommitRequest 请求给对应的 GroupCoordinator，AddOffsetsToTxnHandler 的 <code>handleResponse()</code> 的实现如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleResponse</span><span class="params">(AbstractResponse response)</span> </span>&#123;</span><br><span class="line">    AddOffsetsToTxnResponse addOffsetsToTxnResponse = (AddOffsetsToTxnResponse) response;</span><br><span class="line">    Errors error = addOffsetsToTxnResponse.error();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (error == Errors.NONE) &#123;</span><br><span class="line">        log.debug(<span class="string">"Successfully added partition for consumer group &#123;&#125; to transaction"</span>, builder.consumerGroupId());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// note the result is not completed until the TxnOffsetCommit returns</span></span><br><span class="line">        <span class="comment">//note: AddOffsetsToTnxRequest 之后，还会再发送 TxnOffsetCommitRequest</span></span><br><span class="line">        pendingRequests.add(txnOffsetCommitHandler(result, offsets, builder.consumerGroupId()));</span><br><span class="line">        transactionStarted = <span class="keyword">true</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.COORDINATOR_NOT_AVAILABLE || error == Errors.NOT_COORDINATOR) &#123;</span><br><span class="line">        lookupCoordinator(FindCoordinatorRequest.CoordinatorType.TRANSACTION, transactionalId);</span><br><span class="line">        reenqueue();</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.COORDINATOR_LOAD_IN_PROGRESS || error == Errors.CONCURRENT_TRANSACTIONS) &#123;</span><br><span class="line">        reenqueue();</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.INVALID_PRODUCER_EPOCH) &#123;</span><br><span class="line">        fatalError(error.exception());</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED) &#123;</span><br><span class="line">        fatalError(error.exception());</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.GROUP_AUTHORIZATION_FAILED) &#123;</span><br><span class="line">        abortableError(<span class="keyword">new</span> GroupAuthorizationException(builder.consumerGroupId()));</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        fatalError(<span class="keyword">new</span> KafkaException(<span class="string">"Unexpected error in AddOffsetsToTxnResponse: "</span> + error.message()));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>GroupCoordinator 在收到相应的请求后，会将 offset 信息持久化到 consumer offsets log 中（包含对应的 PID 信息），但是<strong>不会更新到缓存</strong>中，除非这个事务 commit 了，这样的话就可以保证这个 offset 信息对 consumer 是不可见的（没有更新到缓存中的数据是不可见的，通过接口是获取的，这是 GroupCoordinator 本身来保证的）。</p>
<h4 id="事务提交-中断commitTransaction-abortTransaction"><a href="#事务提交-中断commitTransaction-abortTransaction" class="headerlink" title="事务提交/中断commitTransaction()/abortTransaction()"></a>事务提交/中断commitTransaction()/abortTransaction()</h4><p>在一个事务操作处理完成之后，Producer 需要调用 <code>commitTransaction()</code> 或者 <code>abortTransaction()</code> 方法来 commit 或者 abort 这个事务操作。</p>
<h5 id="5-1-EndTxnRequest"><a href="#5-1-EndTxnRequest" class="headerlink" title="5.1. EndTxnRequest"></a>5.1. EndTxnRequest</h5><p>无论是 Commit 还是 Abort，对于 Producer 而言，都是向 TransactionCoordinator 发送 EndTxnRequest 请求，这个请求的内容里会标识是 commit 操作还是 abort 操作，Producer 的 <code>commitTransaction()</code>方法实现如下所示：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//class KafkaProducer</span></span><br><span class="line"><span class="comment">//note: commit 正在进行的事务操作，这个方法在真正发送 commit 之后将会 flush 所有未发送的数据</span></span><br><span class="line"><span class="comment">//note: 如果在发送中遇到任何一个不能修复的错误，这个方法抛出异常，事务也不会被提交，所有 send 必须成功，这个事务才能 commit 成功</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">commitTransaction</span><span class="params">()</span> <span class="keyword">throws</span> ProducerFencedException </span>&#123;</span><br><span class="line">    throwIfNoTransactionManager();</span><br><span class="line">    TransactionalRequestResult result = transactionManager.beginCommit();</span><br><span class="line">    sender.wakeup();</span><br><span class="line">    result.await();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// class TransactionManager</span></span><br><span class="line"><span class="comment">//note: 开始 commit，转移本地本地保存的状态以及发送相应的请求</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> TransactionalRequestResult <span class="title">beginCommit</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    ensureTransactional();</span><br><span class="line">    maybeFailWithError();</span><br><span class="line">    transitionTo(State.COMMITTING_TRANSACTION);</span><br><span class="line">    <span class="keyword">return</span> beginCompletingTransaction(TransactionResult.COMMIT);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Producer 的 <code>abortTransaction()</code> 方法实现如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//class KafkaProducer</span></span><br><span class="line"><span class="comment">//note: 取消正在进行事务，任何没有 flush 的数据都会被丢弃</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">abortTransaction</span><span class="params">()</span> <span class="keyword">throws</span> ProducerFencedException </span>&#123;</span><br><span class="line">    throwIfNoTransactionManager();</span><br><span class="line">    TransactionalRequestResult result = transactionManager.beginAbort();</span><br><span class="line">    sender.wakeup();</span><br><span class="line">    result.await();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// class TransactionManager</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> TransactionalRequestResult <span class="title">beginAbort</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    ensureTransactional();</span><br><span class="line">    <span class="keyword">if</span> (currentState != State.ABORTABLE_ERROR)</span><br><span class="line">        maybeFailWithError();</span><br><span class="line">    transitionTo(State.ABORTING_TRANSACTION);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// We're aborting the transaction, so there should be no need to add new partitions</span></span><br><span class="line">    newPartitionsInTransaction.clear();</span><br><span class="line">    <span class="keyword">return</span> beginCompletingTransaction(TransactionResult.ABORT);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>它们最终都是调用了 TransactionManager 的 <code>beginCompletingTransaction()</code> 方法，这个方法会向其 待发送请求列表 中添加 EndTxnRequest 请求，其实现如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//note: 发送 EndTxnRequest 请求，添加到 pending 队列中</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> TransactionalRequestResult <span class="title">beginCompletingTransaction</span><span class="params">(TransactionResult transactionResult)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!newPartitionsInTransaction.isEmpty())</span><br><span class="line">        enqueueRequest(addPartitionsToTransactionHandler());</span><br><span class="line">    EndTxnRequest.Builder builder = <span class="keyword">new</span> EndTxnRequest.Builder(transactionalId, producerIdAndEpoch.producerId,</span><br><span class="line">            producerIdAndEpoch.epoch, transactionResult);</span><br><span class="line">    EndTxnHandler handler = <span class="keyword">new</span> EndTxnHandler(builder);</span><br><span class="line">    enqueueRequest(handler);</span><br><span class="line">    <span class="keyword">return</span> handler.result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>TransactionCoordinator 在收到 EndTxnRequest 请求后，会做以下处理：</p>
<ol>
<li>更新事务的 meta 信息，状态转移成 PREPARE_COMMIT 或 PREPARE_ABORT，并将事务状态信息持久化到事务日志中；</li>
<li>根据事务 meta 信息，向其涉及到的所有 Topic-Partition 的 leader 发送 Transaction Marker 信息（也就是 WriteTxnMarkerRquest 请求，见下面的 5.2 分析）；</li>
<li>最后将事务状态更新为 COMMIT 或者 ABORT，并将事务的 meta 持久化到事务日志中，也就是 5.3 步骤。</li>
</ol>
<h5 id="5-2-WriteTxnMarkerRquest"><a href="#5-2-WriteTxnMarkerRquest" class="headerlink" title="5.2. WriteTxnMarkerRquest"></a>5.2. WriteTxnMarkerRquest</h5><p>WriteTxnMarkerRquest 是 TransactionCoordinator 收到 Producer 的 EndTxnRequest 请求后向其他 Broker 发送的请求，主要是告诉它们事务已经完成。不论是普通的 Topic-Partition 还是 <code>__consumer_offsets</code>，在收到这个请求后，都会把事务结果（Transaction Marker 的格数据式见前面）持久化到对应的日志文件中，这样下游 Consumer 在消费这个数据时，就知道这个事务是 commit 还是 abort。</p>
<h5 id="5-3-Writing-the-Final-Commit-or-Abort-Message"><a href="#5-3-Writing-the-Final-Commit-or-Abort-Message" class="headerlink" title="5.3. Writing the Final Commit or Abort Message"></a>5.3. Writing the Final Commit or Abort Message</h5><p>当这个事务涉及到所有 Topic-Partition 都已经把这个 marker 信息持久化到日志文件之后，TransactionCoordinator 会将这个事务的状态置为 COMMIT 或 ABORT，并持久化到事务日志文件中，到这里，这个事务操作就算真正完成了，TransactionCoordinator 缓存的很多关于这个事务的数据可以被清除了。</p>
<h3 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h3><p>消费者部分要解决思考问题：</p>
<ol>
<li><strong>如何避免消费者读到未提交的消息；</strong></li>
<li><strong>在事务消息中间（未提交/中断）的非事务消息消费者能否消费到；</strong></li>
<li><strong>如何保证有未完成事务消息和非事务消息夹杂的顺序消费；</strong></li>
<li><strong>如何在哪里过滤中断的事务；</strong></li>
</ol>
<p>消费者有一个 <code>isolation.level</code> 配置，有两个消费策略可选：</p>
<ul>
<li>read_uncommitted:以偏移顺序使用已提交和未提交的消息。</li>
<li>read_committed:仅以偏移量顺序使用非事务性消息或已提交事务性消息。为了维护偏移排序，这个设置意味着我们必须在使用者中缓冲消息，直到看到给定事务中的所有消息。</li>
</ul>
<p>对于read_uncommitted策略有没有事务完全没有影响一样消费；对于read_committed策略，则需要避免消费到。</p>
<h4 id="Last-Stable-Offset（LSO）"><a href="#Last-Stable-Offset（LSO）" class="headerlink" title="Last Stable Offset（LSO）"></a>Last Stable Offset（LSO）</h4><p>为了解决上面的一系列问题，kafka定义了一个新的offset 概念。</p>
<blockquote>
<p>The LSO is defined as the latest offset such that the status of all transactional messages at lower offsets have been determined (i.e. committed or aborted).</p>
</blockquote>
<p><strong>对于一个 Partition 而言，offset 小于 LSO 的数据，全都是已经确定的数据，这个主要是对于事务操作而言，在这个 offset 之前的事务操作都是已经完成的事务（已经 commit 或 abort），如果这个 Partition 没有涉及到事务数据，那么 LSO 就是其 HW（水位）。</strong><br>**<br>Server 处理 read_committed 类型的 Fetch 请求;</p>
<p><strong>如果 Consumer 的消费策略设置的是 read_committed，其在向 Server 发送 Fetch 请求时，Server 端只会返回 LSO 之前的数据，在 LSO 之后的数据不会返回。</strong></p>
<p>通过LSO就能够解决上面的1、2、3问题，那么LSO有没有弊端？<br>当然是有的，那就是 <strong>long transaction，</strong>比如其 first offset 是 1000，另外有几个已经完成的小事务操作，比如：txn1（offset：1100~1200）、txn2（offset：1400~1500），假设此时的 LSO 是 1000，也就是说这个 long transaction 还没有完成，那么已经完成的 txn1、txn2 也会对 consumer 不可见（假设都是 commit 操作），此时<strong>受 long transaction 的影响可能会导致数据有延迟</strong>。</p>
<h4 id="消费过滤"><a href="#消费过滤" class="headerlink" title="消费过滤"></a>消费过滤</h4><ol>
<li>问题4：<strong>在哪里过滤中断的事务</strong></li>
</ol>
<p><strong>kafka是在消费者客户端进行过滤的，也就是abort的消息消费者也会获取.</strong><br>**</p>
<ol start="2">
<li><strong>如果拉取到的数据只有事务的一部分后面的marker数据还未获取，怎么处理</strong>？</li>
</ol>
<p>消费者拉取到的这批数据并不能保证都是完整的事务数据，很有可能是拉取到一个事务的部分数据（marker 数据还没有拉取到），这时候应该怎么办？难道 Consumer 先把这部分数据缓存下来，等后面的 marker 数据到来时再确认数据应该不应该丢弃？（还是又 OOM 的风险）有没有更好的实现方案？</p>
<p>Kafka 的设计总是不会让我们失望，这部分做的优化也是非常高明，Broker 会追踪每个 Partition 涉及到的 abort transactions，Partition 的每个 log segment 都会有一个单独只写的文件（append-only file）来存储 abort transaction 信息，因为 abort transaction 并不是很多，所以这个开销是可以可以接受的，之所以要持久化到磁盘，主要是为了故障后快速恢复，要不然 Broker 需要把这个 Partition 的所有数据都读一遍，才能直到哪些事务是 abort 的，这样的话，开销太大（如果这个 Partition 没有事务操作，就不会生成这个文件）。这个持久化的文件是以 <code>.txnindex</code> 做后缀，前面依然是这个 log segment 的 offset 信息，存储的数据格式如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">TransactionEntry =&gt;</span><br><span class="line">    Version =&gt; int16</span><br><span class="line">    PID =&gt; int64</span><br><span class="line">    FirstOffset =&gt; int64</span><br><span class="line">    LastOffset =&gt; int64</span><br><span class="line">    LastStableOffset =&gt; int64</span><br></pre></td></tr></table></figure></p>
<p>有了这个设计，Consumer 在拉取数据时，Broker 会把这批数据涉及到的所有 abort transaction 信息都返回给 Consumer，Server 端会根据拉取的 offset 范围与 abort transaction 的 offset 做对比，返回涉及到的 abort transaction 集合，其实现如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collectAbortedTxns</span></span>(fetchOffset: <span class="type">Long</span>, upperBoundOffset: <span class="type">Long</span>): <span class="type">TxnIndexSearchResult</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> abortedTransactions = <span class="type">ListBuffer</span>.empty[<span class="type">AbortedTxn</span>]</span><br><span class="line">  <span class="keyword">for</span> ((abortedTxn, _) &lt;- iterator()) &#123;</span><br><span class="line">    <span class="keyword">if</span> (abortedTxn.lastOffset &gt;= fetchOffset &amp;&amp; abortedTxn.firstOffset &lt; upperBoundOffset)</span><br><span class="line">      abortedTransactions += abortedTxn <span class="comment">//note: 这个 abort 的事务有在在这个范围内，就返回</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (abortedTxn.lastStableOffset &gt;= upperBoundOffset)</span><br><span class="line">      <span class="keyword">return</span> <span class="type">TxnIndexSearchResult</span>(abortedTransactions.toList, isComplete = <span class="literal">true</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="type">TxnIndexSearchResult</span>(abortedTransactions.toList, isComplete = <span class="literal">false</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Consumer 在拿到这些数据之后，会进行相应的过滤，大概的判断逻辑如下（Server 端返回的 abort transaction 列表就保存在 <code>abortedTransactions</code> 集合中，<code>abortedProducerIds</code> 最开始时是为空的）：</p>
<ol>
<li>如果这个数据是 control msg（也即是 marker 数据），是 ABORT 的话，那么与这个事务相关的 PID 信息从 <code>abortedProducerIds</code> 集合删掉，是 COMMIT 的话，就忽略（每个这个 PID 对应的 marker 数据收到之后，就从 <code>abortedProducerIds</code> 中清除这个 PID 信息，<strong>清除的意思是这个事务你都解析到事务的结束标记了，后面不会再有该事务了</strong>）；</li>
<li>如果这个数据是正常的数据，把它的 PID 和 offset 信息与 <code>abortedTransactions</code> 队列（有序队列，头部 transaction 的 first offset 最小）第一个 transaction 做比较，如果 PID 相同，并且 offset 大于等于这个 transaction 的 first offset，就将这个 PID 信息添加到 <code>abortedProducerIds</code> 集合中，同时从 <code>abortedTransactions</code> 队列中删除这个 transaction，最后再丢掉这个 batch（它是 abort transaction 的数据）；</li>
<li>检查这个 batch 的 PID 是否在 <code>abortedProducerIds</code> 集合中，在的话，就丢弃，不在的话就返回上层应用。<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">CompletedFetch</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Iterator&lt;? extends RecordBatch&gt; batches;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Set&lt;Long&gt; abortedProducerIds;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> PriorityQueue&lt;FetchResponse.AbortedTransaction&gt; abortedTransactions;</span><br><span class="line">    <span class="keyword">private</span> RecordBatch currentBatch;</span><br><span class="line">    <span class="keyword">private</span> Record lastRecord;</span><br><span class="line">    <span class="keyword">private</span> CloseableIterator&lt;Record&gt; records;</span><br><span class="line">    <span class="comment">// ...省略大部分代码</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">private</span> Record <span class="title">nextFetchedRecord</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (records == <span class="keyword">null</span> || !records.hasNext()) &#123;</span><br><span class="line">                maybeCloseRecordStream();</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (!batches.hasNext()) &#123;</span><br><span class="line">                    <span class="comment">// Message format v2 preserves the last offset in a batch even if the last record is removed</span></span><br><span class="line">                    <span class="comment">// through compaction. By using the next offset computed from the last offset in the batch,</span></span><br><span class="line">                    <span class="comment">// we ensure that the offset of the next fetch will point to the next batch, which avoids</span></span><br><span class="line">                    <span class="comment">// unnecessary re-fetching of the same batch (in the worst case, the consumer could get stuck</span></span><br><span class="line">                    <span class="comment">// fetching the same batch repeatedly).</span></span><br><span class="line">                    <span class="keyword">if</span> (currentBatch != <span class="keyword">null</span>)</span><br><span class="line">                        nextFetchOffset = currentBatch.nextOffset();</span><br><span class="line">                    drain();</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 迭代</span></span><br><span class="line">                currentBatch = batches.next();</span><br><span class="line">                lastEpoch = currentBatch.partitionLeaderEpoch() == RecordBatch.NO_PARTITION_LEADER_EPOCH ?</span><br><span class="line">                    Optional.empty() : Optional.of(currentBatch.partitionLeaderEpoch());</span><br><span class="line"></span><br><span class="line">                maybeEnsureValid(currentBatch);</span><br><span class="line">                <span class="comment">// 事务级别是READ_COMMITTED，而且现在这个batch是有PID(可能有事务)</span></span><br><span class="line">                <span class="keyword">if</span> (isolationLevel == IsolationLevel.READ_COMMITTED &amp;&amp; currentBatch.hasProducerId()) &#123;</span><br><span class="line">                    <span class="comment">// remove from the aborted transaction queue all aborted transactions which have begun</span></span><br><span class="line">                    <span class="comment">// before the current batch's last offset and add the associated producerIds to the</span></span><br><span class="line">                    <span class="comment">// aborted producer set</span></span><br><span class="line">                    <span class="comment">// 更新小于等于offset的abortedTransaction的pid到abortedProducerIds</span></span><br><span class="line">                    consumeAbortedTransactionsUpTo(currentBatch.lastOffset());</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">long</span> producerId = currentBatch.producerId();</span><br><span class="line">                    <span class="comment">// 判断batch是不是Abort标记消息</span></span><br><span class="line">                    <span class="keyword">if</span> (containsAbortMarker(currentBatch)) &#123;</span><br><span class="line">                        <span class="comment">// 将该PID移除，因为已经解析到Abort标记消息了，说明该PID的事务消息已经结束（解析到事务结尾了）</span></span><br><span class="line">                        abortedProducerIds.remove(producerId);</span><br><span class="line">                    <span class="comment">// 判断currentBatch是不是已经abort了，如果是则忽略该消息</span></span><br><span class="line">                    <span class="comment">// 这种情况是解析到事务的中间的消息，这个时候通过abortedProducerIds集合进行判断</span></span><br><span class="line">                    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (isBatchAborted(currentBatch)) &#123;</span><br><span class="line">                        log.debug(<span class="string">"Skipping aborted record batch from partition &#123;&#125; with producerId &#123;&#125; and "</span> +</span><br><span class="line">                                  <span class="string">"offsets &#123;&#125; to &#123;&#125;"</span>,</span><br><span class="line">                                  partition, producerId, currentBatch.baseOffset(), currentBatch.lastOffset());</span><br><span class="line">                        nextFetchOffset = currentBatch.nextOffset();</span><br><span class="line">                        <span class="keyword">continue</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                records = currentBatch.streamingIterator(decompressionBufferSupplier);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                Record record = records.next();</span><br><span class="line">                <span class="comment">// skip any records out of range</span></span><br><span class="line">                <span class="keyword">if</span> (record.offset() &gt;= nextFetchOffset) &#123;</span><br><span class="line">                    <span class="comment">// we only do validation when the message should not be skipped.</span></span><br><span class="line">                    maybeEnsureValid(record);</span><br><span class="line"></span><br><span class="line">                    <span class="comment">// control records are not returned to the user</span></span><br><span class="line">                    <span class="keyword">if</span> (!currentBatch.isControlBatch()) &#123;</span><br><span class="line">                        <span class="keyword">return</span> record;</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        <span class="comment">// Increment the next fetch offset when we skip a control batch.</span></span><br><span class="line">                        nextFetchOffset = record.offset() + <span class="number">1</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 更新小于等于offset的abortedTransaction的pid到abortedProducerIds</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">consumeAbortedTransactionsUpTo</span><span class="params">(<span class="keyword">long</span> offset)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (abortedTransactions == <span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (!abortedTransactions.isEmpty() &amp;&amp; abortedTransactions.peek().firstOffset &lt;= offset) &#123;</span><br><span class="line">            FetchResponse.AbortedTransaction abortedTransaction = abortedTransactions.poll();</span><br><span class="line">            abortedProducerIds.add(abortedTransaction.producerId);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">	<span class="comment">// 是否是abort</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">isBatchAborted</span><span class="params">(RecordBatch batch)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> batch.isTransactional() &amp;&amp; abortedProducerIds.contains(batch.producerId());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 判断batch是不是Abort标记消息</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">containsAbortMarker</span><span class="params">(RecordBatch batch)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!batch.isControlBatch())</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">        Iterator&lt;Record&gt; batchIterator = batch.iterator();</span><br><span class="line">        <span class="keyword">if</span> (!batchIterator.hasNext())</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">        Record firstRecord = batchIterator.next();</span><br><span class="line">        <span class="keyword">return</span> ControlRecordType.ABORT == ControlRecordType.parse(firstRecord.key());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>过滤流程可以参考<a href="https://zhmin.github.io/2019/04/20/kafka-consumer-transaction/" target="_blank" rel="noopener">https://zhmin.github.io/2019/04/20/kafka-consumer-transaction/</a>，实际消费者的代码已经有所不同，我改为2.4.1版本的实现。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>本文很大篇幅都是以下文章中的内容，想要更深入理解可以参考一下文章。</p>
<p><a href="https://www.cnblogs.com/wangzhuxing/p/10125437.html" target="_blank" rel="noopener">kafka系列九、kafka事务原理、事务API和使用场景</a><br><a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-98+-+Exactly+Once+Delivery+and+Transactional+Messaging#KIP-98-ExactlyOnceDeliveryandTransactionalMessaging-DataFlow" target="_blank" rel="noopener">Kafka Exactly-Once Data Flow</a><br><a href="http://matt33.com/2018/11/04/kafka-transaction/" target="_blank" rel="noopener">kafka事务性实现</a><br><a href="https://zhmin.github.io/2019/04/20/kafka-consumer-transaction/" target="_blank" rel="noopener">Kafka Consumer 读取事务消息</a></p>
</div><div class="tags"><a href="/tags/kafka/">kafka</a><a href="/tags/事务/">事务</a></div><div class="post-nav"><a class="pre" href="/2020/05/26/CountDownLatch和CyclicBarrier的区别/">JUC:CountDownLatch和CyclicBarrier的区别</a><a class="next" href="/2020/04/15/kafka消费者rebalance简析/">kafka：消费者rebalance简析</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"><input type="hidden" name="sitesearch" value="https://SvizzerChow.github.io"></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Java/">Java</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Netty/">Netty</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Sentinel/">Sentinel</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/kafka/">kafka</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/redis/">redis</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/sharding-jdbc/">sharding-jdbc</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/分布式/">分布式</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/并发/">并发</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库/">数据库</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法/">算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/线程池/">线程池</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/网络/">网络</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/虚拟机/">虚拟机</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/源码解析/" style="font-size: 15px;">源码解析</a> <a href="/tags/BASE理论/" style="font-size: 15px;">BASE理论</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/并发/" style="font-size: 15px;">并发</a> <a href="/tags/JUC/" style="font-size: 15px;">JUC</a> <a href="/tags/虚拟机/" style="font-size: 15px;">虚拟机</a> <a href="/tags/JavaAgent/" style="font-size: 15px;">JavaAgent</a> <a href="/tags/集合/" style="font-size: 15px;">集合</a> <a href="/tags/可见性/" style="font-size: 15px;">可见性</a> <a href="/tags/内存模型/" style="font-size: 15px;">内存模型</a> <a href="/tags/MESI/" style="font-size: 15px;">MESI</a> <a href="/tags/volatile/" style="font-size: 15px;">volatile</a> <a href="/tags/MySQL/" style="font-size: 15px;">MySQL</a> <a href="/tags/网络/" style="font-size: 15px;">网络</a> <a href="/tags/Netty/" style="font-size: 15px;">Netty</a> <a href="/tags/channel/" style="font-size: 15px;">channel</a> <a href="/tags/ServerBootstrap/" style="font-size: 15px;">ServerBootstrap</a> <a href="/tags/NioEventLoop/" style="font-size: 15px;">NioEventLoop</a> <a href="/tags/启动/" style="font-size: 15px;">启动</a> <a href="/tags/线程模型/" style="font-size: 15px;">线程模型</a> <a href="/tags/读写事件/" style="font-size: 15px;">读写事件</a> <a href="/tags/http/" style="font-size: 15px;">http</a> <a href="/tags/沾包/" style="font-size: 15px;">沾包</a> <a href="/tags/拆包/" style="font-size: 15px;">拆包</a> <a href="/tags/内存/" style="font-size: 15px;">内存</a> <a href="/tags/NIO/" style="font-size: 15px;">NIO</a> <a href="/tags/redis/" style="font-size: 15px;">redis</a> <a href="/tags/NoSQL/" style="font-size: 15px;">NoSQL</a> <a href="/tags/限流/" style="font-size: 15px;">限流</a> <a href="/tags/降级/" style="font-size: 15px;">降级</a> <a href="/tags/熔断/" style="font-size: 15px;">熔断</a> <a href="/tags/Sentinel/" style="font-size: 15px;">Sentinel</a> <a href="/tags/CAP理论/" style="font-size: 15px;">CAP理论</a> <a href="/tags/kafka/" style="font-size: 15px;">kafka</a> <a href="/tags/事务/" style="font-size: 15px;">事务</a> <a href="/tags/TCP/" style="font-size: 15px;">TCP</a> <a href="/tags/生产者/" style="font-size: 15px;">生产者</a> <a href="/tags/原子性/" style="font-size: 15px;">原子性</a> <a href="/tags/long/" style="font-size: 15px;">long</a> <a href="/tags/double/" style="font-size: 15px;">double</a> <a href="/tags/消费者/" style="font-size: 15px;">消费者</a> <a href="/tags/rebalance/" style="font-size: 15px;">rebalance</a> <a href="/tags/coordinator/" style="font-size: 15px;">coordinator</a> <a href="/tags/sentinel/" style="font-size: 15px;">sentinel</a> <a href="/tags/zookeeper/" style="font-size: 15px;">zookeeper</a> <a href="/tags/分布式锁/" style="font-size: 15px;">分布式锁</a> <a href="/tags/数据库/" style="font-size: 15px;">数据库</a> <a href="/tags/分库分表/" style="font-size: 15px;">分库分表</a> <a href="/tags/io/" style="font-size: 15px;">io</a> <a href="/tags/同步/" style="font-size: 15px;">同步</a> <a href="/tags/异步/" style="font-size: 15px;">异步</a> <a href="/tags/线程池/" style="font-size: 15px;">线程池</a> <a href="/tags/Excutors/" style="font-size: 15px;">Excutors</a> <a href="/tags/多线程/" style="font-size: 15px;">多线程</a> <a href="/tags/FutureTask/" style="font-size: 15px;">FutureTask</a> <a href="/tags/AbstractExecutorService/" style="font-size: 15px;">AbstractExecutorService</a> <a href="/tags/ThreadPoolExecutor/" style="font-size: 15px;">ThreadPoolExecutor</a> <a href="/tags/ScheduledThreadPoolExecutor/" style="font-size: 15px;">ScheduledThreadPoolExecutor</a> <a href="/tags/缓存/" style="font-size: 15px;">缓存</a> <a href="/tags/缓存行/" style="font-size: 15px;">缓存行</a> <a href="/tags/轮询/" style="font-size: 15px;">轮询</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a> <a href="/tags/Spring/" style="font-size: 15px;">Spring</a> <a href="/tags/sharding-jdbc/" style="font-size: 15px;">sharding-jdbc</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/05/26/CountDownLatch和CyclicBarrier的区别/">JUC:CountDownLatch和CyclicBarrier的区别</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/07/kafka事务/">kafka：事务原理</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/15/kafka消费者rebalance简析/">kafka：消费者rebalance简析</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/09/kafka生产者客户端发送逻辑简析/">kafka：生产者客户端发送逻辑简析</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/19/Netty之旅30对象池Recycler/">Netty解析二十八：Netty对象池Recycler</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/18/Netty之旅29PooledByteBufAllocator/">Netty解析二十七：Netty内存分配PooledByteBufAllocator</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/18/Netty之旅28PooledByteBuf/">Netty解析二十六：Netty内存分配PooledByteBuf</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/16/Netty之旅27PoolArena/">Netty解析二十五：Netty内存分配PoolArena</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/13/Netty之旅26PoolChunkList/">Netty解析二十四：Netty内存分配PoolChunkList</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/12/Netty之旅25PoolSubpage/">Netty解析二十三：Netty内存分配PoolSubpage</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2017-2020 <a href="/." rel="nofollow">SvizzerChow's Blog.</a><a rel="nofollow" target="_blank" href="http://www.beian.miit.gov.cn"> 浙ICP备18053179号</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>